<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Timur Sattarov" />

<meta name="date" content="2015-01-14" />

<title>Weight Lifting Exercises Dataset</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link href="data:text/css,body%20%7B%0A%20%20background%2Dcolor%3A%20%23fff%3B%0A%20%20margin%3A%201em%20auto%3B%0A%20%20max%2Dwidth%3A%20700px%3B%0A%20%20overflow%3A%20visible%3B%0A%20%20padding%2Dleft%3A%202em%3B%0A%20%20padding%2Dright%3A%202em%3B%0A%20%20font%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0A%20%20font%2Dsize%3A%2014px%3B%0A%20%20line%2Dheight%3A%201%2E35%3B%0A%7D%0A%0A%23header%20%7B%0A%20%20text%2Dalign%3A%20center%3B%0A%7D%0A%0A%23TOC%20%7B%0A%20%20clear%3A%20both%3B%0A%20%20margin%3A%200%200%2010px%2010px%3B%0A%20%20padding%3A%204px%3B%0A%20%20width%3A%20400px%3B%0A%20%20border%3A%201px%20solid%20%23CCCCCC%3B%0A%20%20border%2Dradius%3A%205px%3B%0A%0A%20%20background%2Dcolor%3A%20%23f6f6f6%3B%0A%20%20font%2Dsize%3A%2013px%3B%0A%20%20line%2Dheight%3A%201%2E3%3B%0A%7D%0A%20%20%23TOC%20%2Etoctitle%20%7B%0A%20%20%20%20font%2Dweight%3A%20bold%3B%0A%20%20%20%20font%2Dsize%3A%2015px%3B%0A%20%20%20%20margin%2Dleft%3A%205px%3B%0A%20%20%7D%0A%0A%20%20%23TOC%20ul%20%7B%0A%20%20%20%20padding%2Dleft%3A%2040px%3B%0A%20%20%20%20margin%2Dleft%3A%20%2D1%2E5em%3B%0A%20%20%20%20margin%2Dtop%3A%205px%3B%0A%20%20%20%20margin%2Dbottom%3A%205px%3B%0A%20%20%7D%0A%20%20%23TOC%20ul%20ul%20%7B%0A%20%20%20%20margin%2Dleft%3A%20%2D2em%3B%0A%20%20%7D%0A%20%20%23TOC%20li%20%7B%0A%20%20%20%20line%2Dheight%3A%2016px%3B%0A%20%20%7D%0A%0Atable%20%7B%0A%20%20margin%3A%201em%20auto%3B%0A%20%20border%2Dwidth%3A%201px%3B%0A%20%20border%2Dcolor%3A%20%23DDDDDD%3B%0A%20%20border%2Dstyle%3A%20outset%3B%0A%20%20border%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0A%20%20border%2Dwidth%3A%202px%3B%0A%20%20padding%3A%205px%3B%0A%20%20border%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0A%20%20border%2Dwidth%3A%201px%3B%0A%20%20border%2Dstyle%3A%20inset%3B%0A%20%20line%2Dheight%3A%2018px%3B%0A%20%20padding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0A%20%20border%2Dleft%2Dstyle%3A%20none%3B%0A%20%20border%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0A%20%20background%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0A%0Ap%20%7B%0A%20%20margin%3A%200%2E5em%200%3B%0A%7D%0A%0Ablockquote%20%7B%0A%20%20background%2Dcolor%3A%20%23f6f6f6%3B%0A%20%20padding%3A%200%2E25em%200%2E75em%3B%0A%7D%0A%0Ahr%20%7B%0A%20%20border%2Dstyle%3A%20solid%3B%0A%20%20border%3A%20none%3B%0A%20%20border%2Dtop%3A%201px%20solid%20%23777%3B%0A%20%20margin%3A%2028px%200%3B%0A%7D%0A%0Adl%20%7B%0A%20%20margin%2Dleft%3A%200%3B%0A%7D%0A%20%20dl%20dd%20%7B%0A%20%20%20%20margin%2Dbottom%3A%2013px%3B%0A%20%20%20%20margin%2Dleft%3A%2013px%3B%0A%20%20%7D%0A%20%20dl%20dt%20%7B%0A%20%20%20%20font%2Dweight%3A%20bold%3B%0A%20%20%7D%0A%0Aul%20%7B%0A%20%20margin%2Dtop%3A%200%3B%0A%7D%0A%20%20ul%20li%20%7B%0A%20%20%20%20list%2Dstyle%3A%20circle%20outside%3B%0A%20%20%7D%0A%20%20ul%20ul%20%7B%0A%20%20%20%20margin%2Dbottom%3A%200%3B%0A%20%20%7D%0A%0Apre%2C%20code%20%7B%0A%20%20background%2Dcolor%3A%20%23f7f7f7%3B%0A%20%20border%2Dradius%3A%203px%3B%0A%20%20color%3A%20%23333%3B%0A%7D%0Apre%20%7B%0A%20%20white%2Dspace%3A%20pre%2Dwrap%3B%20%20%20%20%2F%2A%20Wrap%20long%20lines%20%2A%2F%0A%20%20border%2Dradius%3A%203px%3B%0A%20%20margin%3A%205px%200px%2010px%200px%3B%0A%20%20padding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0A%20%20background%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0A%0Acode%20%7B%0A%20%20font%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0A%20%20font%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0A%20%20padding%3A%202px%200px%3B%0A%7D%0A%0Adiv%2Efigure%20%7B%0A%20%20text%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0A%20%20background%2Dcolor%3A%20%23FFFFFF%3B%0A%20%20padding%3A%202px%3B%0A%20%20border%3A%201px%20solid%20%23DDDDDD%3B%0A%20%20border%2Dradius%3A%203px%3B%0A%20%20border%3A%201px%20solid%20%23CCCCCC%3B%0A%20%20margin%3A%200%205px%3B%0A%7D%0A%0Ah1%20%7B%0A%20%20margin%2Dtop%3A%200%3B%0A%20%20font%2Dsize%3A%2035px%3B%0A%20%20line%2Dheight%3A%2040px%3B%0A%7D%0A%0Ah2%20%7B%0A%20%20border%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0A%20%20padding%2Dtop%3A%2010px%3B%0A%20%20padding%2Dbottom%3A%202px%3B%0A%20%20font%2Dsize%3A%20145%25%3B%0A%7D%0A%0Ah3%20%7B%0A%20%20border%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0A%20%20padding%2Dtop%3A%2010px%3B%0A%20%20font%2Dsize%3A%20120%25%3B%0A%7D%0A%0Ah4%20%7B%0A%20%20border%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0A%20%20margin%2Dleft%3A%208px%3B%0A%20%20font%2Dsize%3A%20105%25%3B%0A%7D%0A%0Ah5%2C%20h6%20%7B%0A%20%20border%2Dbottom%3A%201px%20solid%20%23ccc%3B%0A%20%20font%2Dsize%3A%20105%25%3B%0A%7D%0A%0Aa%20%7B%0A%20%20color%3A%20%230033dd%3B%0A%20%20text%2Ddecoration%3A%20none%3B%0A%7D%0A%20%20a%3Ahover%20%7B%0A%20%20%20%20color%3A%20%236666ff%3B%20%7D%0A%20%20a%3Avisited%20%7B%0A%20%20%20%20color%3A%20%23800080%3B%20%7D%0A%20%20a%3Avisited%3Ahover%20%7B%0A%20%20%20%20color%3A%20%23BB00BB%3B%20%7D%0A%20%20a%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0A%20%20%20%20text%2Ddecoration%3A%20underline%3B%20%7D%0A%20%20a%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0A%20%20%20%20text%2Ddecoration%3A%20underline%3B%20%7D%0A%0A%2F%2A%20Class%20described%20in%20https%3A%2F%2Fbenjeffrey%2Ecom%2Fposts%2Fpandoc%2Dsyntax%2Dhighlighting%2Dcss%0A%20%20%20Colours%20from%20https%3A%2F%2Fgist%2Egithub%2Ecom%2Frobsimmons%2F1172277%20%2A%2F%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%2F%2A%20Keyword%20%2A%2F%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%2F%2A%20DataType%20%2A%2F%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%2F%2A%20DecVal%20%28decimal%20values%29%20%2A%2F%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%2F%2A%20BaseN%20%2A%2F%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%2F%2A%20Float%20%2A%2F%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%2F%2A%20Char%20%2A%2F%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%2F%2A%20String%20%2A%2F%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%2F%2A%20Comment%20%2A%2F%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%2F%2A%20OtherToken%20%2A%2F%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%2F%2A%20AlertToken%20%2A%2F%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%2F%2A%20Function%20calls%20%2A%2F%20%0Acode%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%2F%2A%20ErrorTok%20%2A%2F%0A%0A" rel="stylesheet" type="text/css" />

</head>

<body>



<div id="header">
<h1 class="title">Weight Lifting Exercises Dataset</h1>
<h4 class="author"><em>Timur Sattarov</em></h4>
<h4 class="date"><em>2015-01-14</em></h4>
</div>


<p>The “caret” package was chosen to find an appropriate machine learning algorithm with an appropriate tuning parameters.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span> (caret)</code></pre>
<pre><code>## Loading required package: lattice
## Loading required package: ggplot2</code></pre>
<p>As a first step was loading the dataset, removing the empty columns and columns with “NA” values.</p>
<pre class="sourceCode r"><code class="sourceCode r">pml_training =<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;pml-training.csv&quot;</span>, <span class="dt">header =</span> T, <span class="dt">na.string=</span><span class="kw">c</span>(<span class="st">&quot;&quot;</span>,<span class="st">&quot;NA&quot;</span>));
pml_testing =<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;pml-testing.csv&quot;</span>, <span class="dt">header =</span> T, <span class="dt">na.string=</span><span class="kw">c</span>(<span class="st">&quot;&quot;</span>,<span class="st">&quot;NA&quot;</span>));

pml_training =<span class="st"> </span>pml_training[ , !<span class="st"> </span><span class="kw">apply</span>( pml_training , <span class="dv">2</span> , function(x) <span class="kw">any</span>(<span class="kw">is.na</span>(x)) ) ]
pml_testing =<span class="st"> </span>pml_testing[ , !<span class="st"> </span><span class="kw">apply</span>( pml_testing , <span class="dv">2</span> , function(x) <span class="kw">any</span>(<span class="kw">is.na</span>(x)) ) ]</code></pre>
<p>As a next step some of the columns should be removed as well since they don’t provide any information necessary for creating the classification model.</p>
<pre class="sourceCode r"><code class="sourceCode r">pml_training =<span class="st"> </span>pml_training[,<span class="dv">8</span>:<span class="dv">60</span>]
pml_testing =<span class="st"> </span>pml_testing[,<span class="dv">8</span>:<span class="dv">59</span>]</code></pre>
<p>Before starting to build a classification model the training dataset was split into training and test sets, giving 75% of the samples to the training set and 25% to the test set.</p>
<pre class="sourceCode r"><code class="sourceCode r">inTrain =<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y=</span>pml_training$classe, <span class="dt">p=</span><span class="fl">0.75</span>, <span class="dt">list=</span><span class="ot">FALSE</span>)
training =<span class="st"> </span>pml_training[inTrain,]
testing =<span class="st"> </span>pml_training[-inTrain,]</code></pre>
<p>In addition dimensionality reduction was applied to the training dataset to see how the samples of different classes are distributed. For this Principal Component Analisys was applied and first two principal components were chosen to plot it in 2D.</p>
<pre class="sourceCode r"><code class="sourceCode r">preProc =<span class="st"> </span><span class="kw">preProcess</span>(training[,-<span class="dv">53</span>], <span class="dt">method =</span> <span class="st">&quot;pca&quot;</span>, <span class="dt">pcaComp=</span><span class="dv">2</span>)
training_preProcPCA =<span class="st"> </span><span class="kw">predict</span>(preProc, training[,-<span class="dv">53</span>])
<span class="kw">plot</span>(training_preProcPCA[,<span class="dv">1</span>], training_preProcPCA[,<span class="dv">2</span>], <span class="dt">col=</span>training$classe, <span class="dt">xlab=</span><span class="st">&quot;PC_1&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;PC_2&quot;</span>)</code></pre>
<p><img src="data:image/png;base64,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" /></p>
<p>The plot shows that the samples are distributed in 5 clusters, however none of them has all the samples of one class. Each cluster has samples of different classes.</p>
<p>Different kinds of machine learning algorithms were applied to build a suitable model with high accuracy level. The tuning of the models included different types of preprocessing such as: scaling, centering, PCA. In addition for each classification algorithm a variety of tuning parameters was applied, for example in Neural Network it’s a number of hidden layers and a decay. Regarding the resampling methods preference was given mostly to k-fold cross validation and bootstraping. Out of all applied algorithms “Random Forests” gave the highest accuracy value of 99.3%.</p>
<pre class="sourceCode r"><code class="sourceCode r">trainControl =<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">number =</span> <span class="dv">10</span>, <span class="dt">repeats =</span> <span class="dv">3</span>, <span class="dt">verboseIter =</span> T)
modelFit =<span class="st"> </span><span class="kw">train</span>(classe ~., <span class="dt">data=</span>training, <span class="dt">method=</span><span class="st">&quot;rf&quot;</span>,<span class="dt">preProcess=</span><span class="kw">c</span>(<span class="st">&quot;scale&quot;</span>,<span class="st">&quot;center&quot;</span>),
<span class="dt">trControl =</span> trainControl)
modelFit

Random Forest 

<span class="dv">14718</span> samples
   <span class="dv">52</span> predictor
    <span class="dv">5</span> classes:<span class="st"> 'A'</span>, <span class="st">'B'</span>, <span class="st">'C'</span>, <span class="st">'D'</span>, <span class="st">'E'</span> 

Pre-processing:<span class="st"> </span>scaled, centered 
Resampling:<span class="st"> </span>Cross-<span class="kw">Validated</span> (<span class="dv">10</span> fold, repeated <span class="dv">3</span> times) 

Summary of sample sizes:<span class="st"> </span><span class="dv">13247</span>, <span class="dv">13246</span>, <span class="dv">13247</span>, <span class="dv">13246</span>, <span class="dv">13248</span>, <span class="dv">13245</span>, ... 

Resampling results across tuning parameters:

<span class="st">  </span>mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   
   <span class="dv">2</span>    <span class="fl">0.9932963</span>  <span class="fl">0.9915197</span>  <span class="fl">0.002101237</span>  <span class="fl">0.002658269</span>
  <span class="dv">27</span>    <span class="fl">0.9929112</span>  <span class="fl">0.9910328</span>  <span class="fl">0.002138901</span>  <span class="fl">0.002705497</span>
  <span class="dv">52</span>    <span class="fl">0.9853696</span>  <span class="fl">0.9814918</span>  <span class="fl">0.002807063</span>  <span class="fl">0.003551657</span>

Accuracy was used to select the optimal model using  the largest value.
The final value used for the model was mtry =<span class="st"> </span><span class="dv">2</span>. </code></pre>
<p>When the model was applied to the test dataset it made almost perfect classification. The statistics below shows it clearly.</p>
<pre class="sourceCode r"><code class="sourceCode r">predictions =<span class="st"> </span><span class="kw">predict</span>(modelFit, <span class="dt">newdata =</span> testing)
<span class="kw">confusionMatrix</span>(predictions, testing$classe)

Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A <span class="dv">1395</span>    <span class="dv">6</span>    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span>
         B    <span class="dv">0</span>  <span class="dv">941</span>    <span class="dv">2</span>    <span class="dv">0</span>    <span class="dv">0</span>
         C    <span class="dv">0</span>    <span class="dv">2</span>  <span class="dv">851</span>    <span class="dv">9</span>    <span class="dv">0</span>
         D    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">2</span>  <span class="dv">795</span>    <span class="dv">1</span>
         E    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span>  <span class="dv">900</span>

Overall Statistics
                                          
               Accuracy :<span class="st"> </span><span class="fl">0.9955</span>          
                 <span class="dv">95</span>% CI :<span class="st"> </span>(<span class="fl">0.9932</span>, <span class="fl">0.9972</span>)
    No Information Rate :<span class="st"> </span><span class="fl">0.2845</span>          
    P-Value [Acc &gt;<span class="st"> </span>NIR] :<span class="st"> </span><span class="er">&lt;</span><span class="st"> </span><span class="fl">2.2e-16</span>       
                                          
                  Kappa :<span class="st"> </span><span class="fl">0.9943</span>          
 Mcnemar<span class="st">'s Test P-Value : NA              </span>

<span class="st">Statistics by Class:</span>

<span class="st">                     Class: A Class: B Class: C Class: D Class: E</span>
<span class="st">Sensitivity            1.0000   0.9916   0.9953   0.9888   0.9989</span>
<span class="st">Specificity            0.9983   0.9995   0.9973   0.9993   1.0000</span>
<span class="st">Pos Pred Value         0.9957   0.9979   0.9872   0.9962   1.0000</span>
<span class="st">Neg Pred Value         1.0000   0.9980   0.9990   0.9978   0.9998</span>
<span class="st">Prevalence             0.2845   0.1935   0.1743   0.1639   0.1837</span>
<span class="st">Detection Rate         0.2845   0.1919   0.1735   0.1621   0.1835</span>
<span class="st">Detection Prevalence   0.2857   0.1923   0.1758   0.1627   0.1835</span>
<span class="st">Balanced Accuracy      0.9991   0.9955   0.9963   0.9940   0.9994</span></code></pre>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
